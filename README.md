# Open Source LLMs

| **Model**          | **Parameters**       | **License**      | **Key Features**                                                                 | **Source**              |  
|---------------------|----------------------|------------------|---------------------------------------------------------------------------------|-------------------------|  
| **Mistral**         | 3B–124B             | Apache 2.0       | High performance for edge/on-device AI, native function calling, MoE support.  | Mistral AI             |  
| **StarCoder2**      | 3B–15B              | Apache 2.0       | Code generation, multi-language programming.                                   | BigCode                |  
| **Yi**              | 6B–34B              | Apache 2.0       | Bilingual (English/Chinese), math/code tasks, 200k context window.             | 01.AI                  |  
| **Qwen2.5**         | 0.5B–72B            | Apache 2.0*      | Structured data processing, multilingual, 128k context.                        | Alibaba                |  
| **OPT**             | 125M–175B           | Apache 2.0       | Zero-shot capabilities, flexible deployment.                                   | Meta                   |  
| **Dolly**           | 3B–12B              | MIT              | Instruction-tuned, ideal for chatbots and task-oriented dialogue.              | Databricks             |  
| **OpenChatKit**     | 1.3B                | MIT              | Ethical alignment, reduced toxicity, privacy-focused.                          | Together Computer      |  
| **OLMo**            | 7B                  | Apache 2.0       | Transparency-focused, reproducible training code.                              | Allen Institute for AI |  
| **RWKV**            | Up to 14B           | Apache 2.0       | RNN-based, infinite context length, efficient inference.                       | RWKV Foundation        |  

### Notes:  
- **Permissive Licenses** (Apache 2.0/MIT): Allow commercial use, modification, and redistribution with minimal restrictions (attribution required for MIT/BSD).  
- *Qwen2.5*: Some variants use the Apache 2.0 license, while others use the proprietary Qwen License. Verify specific model versions.  
- Excluded models with restrictive licenses (e.g., Llama Community License, OpenRAIL-M, TII Falcon License, or CC BY-SA-4.0).  

### Recommended for Commercial Use:  
- **Mistral** (Apache 2.0): Balances performance and scalability.  
- **Dolly** (MIT): Simple integration for dialogue systems.  
- **StarCoder2** (Apache 2.0): Best for code-generation tasks.  
